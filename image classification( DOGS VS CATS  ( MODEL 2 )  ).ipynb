{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12501/12501 [02:41<00:00, 77.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 12501/12501 [02:31<00:00, 82.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"D:\\ML\\PetImages\"\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "IMG_SIZE = 50\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            \n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24946, 50, 50, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[105],\n",
       "        [105],\n",
       "        [100],\n",
       "        ...,\n",
       "        [121],\n",
       "        [124],\n",
       "        [101]],\n",
       "\n",
       "       [[129],\n",
       "        [122],\n",
       "        [117],\n",
       "        ...,\n",
       "        [129],\n",
       "        [125],\n",
       "        [132]],\n",
       "\n",
       "       [[117],\n",
       "        [118],\n",
       "        [117],\n",
       "        ...,\n",
       "        [ 63],\n",
       "        [ 82],\n",
       "        [ 89]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 57],\n",
       "        [ 58],\n",
       "        [ 61],\n",
       "        ...,\n",
       "        [116],\n",
       "        [109],\n",
       "        [105]],\n",
       "\n",
       "       [[ 53],\n",
       "        [ 50],\n",
       "        [ 49],\n",
       "        ...,\n",
       "        [ 75],\n",
       "        [106],\n",
       "        [103]],\n",
       "\n",
       "       [[ 45],\n",
       "        [ 50],\n",
       "        [ 44],\n",
       "        ...,\n",
       "        [107],\n",
       "        [ 95],\n",
       "        [ 94]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==1.15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 14s 822us/sample - loss: 0.6327 - accuracy: 0.6329 - val_loss: 0.5770 - val_accuracy: 0.6978\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 7s 400us/sample - loss: 0.5316 - accuracy: 0.7353 - val_loss: 0.5823 - val_accuracy: 0.7028\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 7s 389us/sample - loss: 0.4774 - accuracy: 0.7726 - val_loss: 0.4726 - val_accuracy: 0.7758\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 7s 392us/sample - loss: 0.4370 - accuracy: 0.7965 - val_loss: 0.4842 - val_accuracy: 0.7782\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 7s 393us/sample - loss: 0.4034 - accuracy: 0.8154 - val_loss: 0.4461 - val_accuracy: 0.7878\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 7s 402us/sample - loss: 0.3701 - accuracy: 0.8327 - val_loss: 0.4391 - val_accuracy: 0.7982\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 7s 407us/sample - loss: 0.3440 - accuracy: 0.8458 - val_loss: 0.4351 - val_accuracy: 0.8004\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 7s 394us/sample - loss: 0.3151 - accuracy: 0.8619 - val_loss: 0.4551 - val_accuracy: 0.7990\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 7s 395us/sample - loss: 0.2935 - accuracy: 0.8720 - val_loss: 0.4774 - val_accuracy: 0.7950\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 7s 395us/sample - loss: 0.2675 - accuracy: 0.8848 - val_loss: 0.4714 - val_accuracy: 0.7992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x134d7ca8e88>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "\n",
    "X = X/255.0 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dogs vs cats (model_2)\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('dogs vs cats (model_2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loaded_model = tf.keras.models.load_model('tf_lite.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = [\"Dog\", \"Cat\"]  # will use this to convert prediction num to string value\n",
    "import cv2\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # return the image with shaping that TF wants.\n",
    "inputs = prepare(r'C:\\Users\\Gaming\\Jupyter Notebook\\Test Images\\1.jpg')\n",
    "prediction = loaded_model.predict(inputs)  # REMEMBER YOU'RE PASSING A LIST OF THINGS YOU WISH TO PREDICT\n",
    "\n",
    "# prediction\n",
    "\n",
    "if prediction == 0:\n",
    "    predict = 'dog'\n",
    "else:\n",
    "    predict = 'cat'\n",
    "\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model\n",
    "export_dir = r'C:\\Users\\Gaming\\Jupyter Notebook\\tf_lite.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378320"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "tflite_model_file =pathlib.Path(r'C:\\Users\\Gaming\\Jupyter Notebook\\model2.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
