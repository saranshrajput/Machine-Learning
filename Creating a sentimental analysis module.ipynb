{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'short_reviews/positive.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-63c71e23e008>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mshort_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"short_reviews/positive.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[0mshort_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"short_reviews/negative.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'short_reviews/positive.txt'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "    \n",
    "short_pos = open(\"short_reviews/positive.txt\",\"r\").read()\n",
    "short_neg = open(\"short_reviews/negative.txt\",\"r\").read()\n",
    "\n",
    "# move this up here\n",
    "all_words = []\n",
    "documents = []\n",
    "\n",
    "\n",
    "#  j is adject, r is adverb, and v is verb\n",
    "#allowed_word_types = [\"J\",\"R\",\"V\"]\n",
    "allowed_word_types = [\"J\"]\n",
    "\n",
    "for p in short_pos.split('\\n'):\n",
    "    documents.append( (p, \"pos\") )\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "    \n",
    "for p in short_neg.split('\\n'):\n",
    "    documents.append( (p, \"neg\") )\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "\n",
    "\n",
    "save_documents = open(\"pickled_algos/documents.pickle\",\"wb\")\n",
    "pickle.dump(documents, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "\n",
    "save_word_features = open(\"pickled_algos/word_features5k.pickle\",\"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "print(len(featuresets))\n",
    "\n",
    "testing_set = featuresets[10000:]\n",
    "training_set = featuresets[:10000]\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "###############\n",
    "save_classifier = open(\"pickled_algos/originalnaivebayes5k.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/MNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(MNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/BernoulliNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/LogisticRegression_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LogisticRegression_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/LinearSVC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LinearSVC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "# ##NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "# ##NuSVC_classifier.train(training_set)\n",
    "# ##print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "# SGDC_classifier = SklearnClassifier(SGDClassifier())\n",
    "# SGDC_classifier.train(training_set)\n",
    "# print(\"SGDClassifier accuracy percent:\",nltk.classify.accuracy(SGDC_classifier, testing_set)*100)\n",
    "\n",
    "# save_classifier = open(\"pickled_algos/SGDC_classifier5k.pickle\",\"wb\")\n",
    "# pickle.dump(SGDC_classifier, save_classifier)\n",
    "# save_classifier.close()\n",
    "\n",
    "# Now, you just need to run this one time. You can always run it again if you wanted, but now, you are ready to create the sentiment analysis module. Here's the file that we're going to call sentiment_mod.py\n",
    "\n",
    "# #File: sentiment_mod.py\n",
    "\n",
    "# import nltk\n",
    "# import random\n",
    "# #from nltk.corpus import movie_reviews\n",
    "# from nltk.classify.scikitlearn import SklearnClassifier\n",
    "# import pickle\n",
    "# from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "# from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "# from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "# from nltk.classify import ClassifierI\n",
    "# from statistics import mode\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# class VoteClassifier(ClassifierI):\n",
    "#     def __init__(self, *classifiers):\n",
    "#         self._classifiers = classifiers\n",
    "\n",
    "#     def classify(self, features):\n",
    "#         votes = []\n",
    "#         for c in self._classifiers:\n",
    "#             v = c.classify(features)\n",
    "#             votes.append(v)\n",
    "#         return mode(votes)\n",
    "\n",
    "#     def confidence(self, features):\n",
    "#         votes = []\n",
    "#         for c in self._classifiers:\n",
    "#             v = c.classify(features)\n",
    "#             votes.append(v)\n",
    "\n",
    "#         choice_votes = votes.count(mode(votes))\n",
    "#         conf = choice_votes / len(votes)\n",
    "#         return conf\n",
    "\n",
    "\n",
    "# documents_f = open(\"pickled_algos/documents.pickle\", \"rb\")\n",
    "# documents = pickle.load(documents_f)\n",
    "# documents_f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# word_features5k_f = open(\"pickled_algos/word_features5k.pickle\", \"rb\")\n",
    "# word_features = pickle.load(word_features5k_f)\n",
    "# word_features5k_f.close()\n",
    "\n",
    "\n",
    "# def find_features(document):\n",
    "#     words = word_tokenize(document)\n",
    "#     features = {}\n",
    "#     for w in word_features:\n",
    "#         features[w] = (w in words)\n",
    "\n",
    "#     return features\n",
    "\n",
    "\n",
    "\n",
    "# featuresets_f = open(\"pickled_algos/featuresets.pickle\", \"rb\")\n",
    "# featuresets = pickle.load(featuresets_f)\n",
    "# featuresets_f.close()\n",
    "\n",
    "# random.shuffle(featuresets)\n",
    "# print(len(featuresets))\n",
    "\n",
    "# testing_set = featuresets[10000:]\n",
    "# training_set = featuresets[:10000]\n",
    "\n",
    "\n",
    "\n",
    "# open_file = open(\"pickled_algos/originalnaivebayes5k.pickle\", \"rb\")\n",
    "# classifier = pickle.load(open_file)\n",
    "# open_file.close()\n",
    "\n",
    "\n",
    "# open_file = open(\"pickled_algos/MNB_classifier5k.pickle\", \"rb\")\n",
    "# MNB_classifier = pickle.load(open_file)\n",
    "# open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "# open_file = open(\"pickled_algos/BernoulliNB_classifier5k.pickle\", \"rb\")\n",
    "# BernoulliNB_classifier = pickle.load(open_file)\n",
    "# open_file.close()\n",
    "\n",
    "\n",
    "# open_file = open(\"pickled_algos/LogisticRegression_classifier5k.pickle\", \"rb\")\n",
    "# LogisticRegression_classifier = pickle.load(open_file)\n",
    "# open_file.close()\n",
    "\n",
    "\n",
    "# open_file = open(\"pickled_algos/LinearSVC_classifier5k.pickle\", \"rb\")\n",
    "# LinearSVC_classifier = pickle.load(open_file)\n",
    "# open_file.close()\n",
    "\n",
    "\n",
    "# open_file = open(\"pickled_algos/SGDC_classifier5k.pickle\", \"rb\")\n",
    "# SGDC_classifier = pickle.load(open_file)\n",
    "# open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# voted_classifier = VoteClassifier(\n",
    "#                                   classifier,\n",
    "#                                   LinearSVC_classifier,\n",
    "#                                   MNB_classifier,\n",
    "#                                   BernoulliNB_classifier,\n",
    "#                                   LogisticRegression_classifier)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def sentiment(text):\n",
    "#     feats = find_features(text)\n",
    "#     return voted_classifier.classify(feats),voted_classifier.confidence(feats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
