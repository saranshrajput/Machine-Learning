{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Hello My name is Saransh. I am a student at SRM University'\n",
    "tokens = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Saransh',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'student',\n",
       " 'at',\n",
       " 'SRM',\n",
       " 'University']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello My name is Saransh.', 'I am a student at SRM University']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'),\n",
       " ('My', 'NNP'),\n",
       " ('name', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('Saransh', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('student', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('SRM', 'NNP'),\n",
       " ('University', 'NNP')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PERSON Hello/NNP)\n"
     ]
    }
   ],
   "source": [
    "print(entities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv('D:\\Data_Sets\\IMDB Dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "#TQDM is a progress bar library with good support for nested loops and Jupyter/IPython notebooks.\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import random\n",
    "# from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "#set random seed for the session and also for tensorflow that runs in background for keras\n",
    "# set_random_seed(123)\n",
    "# random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= pd.read_csv(\"D:\\Data_Sets\\Movie Reviews\\TRAIN.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"D:\\Data_Sets\\Movie Reviews\\TEST.tsv\", sep=\"\\t\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(df):\n",
    "    reviews = []\n",
    "\n",
    "    for sent in tqdm(df['Phrase']):\n",
    "        \n",
    "        #remove html content\n",
    "        review_text = BeautifulSoup(sent).get_text()\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(review_text.lower())\n",
    "    \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        reviews.append(lemma_words)\n",
    "\n",
    "    return(reviews)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 1/156060 [00:03<157:17:48,  3.63s/it]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      "  0%|▏                                                                         | 300/156060 [00:03<53:52:39,  1.25s/it]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"source\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      "  1%|▍                                                                          | 827/156060 [00:04<9:03:31,  4.76it/s]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      "  2%|█▏                                                                         | 2408/156060 [00:05<05:00, 510.48it/s]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"music\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      "  2%|█▎                                                                         | 2717/156060 [00:06<03:23, 754.03it/s]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"recent\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      "  3%|██▍                                                                       | 5106/156060 [00:08<02:26, 1028.64it/s]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"pictures\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      "  4%|███                                                                       | 6348/156060 [00:09<02:26, 1019.50it/s]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"videos\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      " 20%|██████████████▌                                                          | 31005/156060 [00:33<02:03, 1015.48it/s]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"searches\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      " 57%|█████████████████████████████████████████▌                               | 88919/156060 [01:31<01:06, 1008.89it/s]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"documents\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      " 73%|████████████████████████████████████████████████████▊                   | 114452/156060 [01:57<00:41, 1002.42it/s]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"pictures .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      " 76%|███████████████████████████████████████████████████████▋                 | 118991/156060 [02:01<00:37, 991.55it/s]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"favorites\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 156060/156060 [02:39<00:00, 979.84it/s]\n",
      " 46%|██████████████████████████████████▋                                        | 30612/66292 [00:30<00:35, 999.86it/s]E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\bs4\\__init__.py:312: UserWarning: \"contacts\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % self._decode_markup(markup)\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 66292/66292 [01:06<00:00, 1002.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156060\n",
      "66292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_sentences = clean_sentences(train)\n",
    "test_sentences = clean_sentences(test)\n",
    "print(len(train_sentences))\n",
    "print(len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=train.Sentiment.values\n",
    "y_target=to_categorical(target)\n",
    "num_classes=y_target.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(train_sentences,y_target,test_size=0.2,stratify=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 124848/124848 [00:00<00:00, 342506.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13739\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#It is needed for initializing tokenizer of keras and subsequent padding\n",
    "\n",
    "unique_words = set()\n",
    "len_max = 0\n",
    "\n",
    "for sent in tqdm(X_train):\n",
    "    \n",
    "    unique_words.update(sent)\n",
    "    \n",
    "    if(len_max<len(sent)):\n",
    "        len_max = len(sent)\n",
    "        \n",
    "#length of the list of unique_words gives the no of unique words\n",
    "print(len(list(unique_words)))\n",
    "print(len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124848, 48) (31212, 48) (66292, 48)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "#texts_to_sequences(texts)\n",
    "\n",
    "    # Arguments- texts: list of texts to turn to sequences.\n",
    "    #Return: list of sequences (one per text input).\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "#padding done to equalize the lengths of all input reviews. LSTM networks needs all inputs to be same length.\n",
    "#Therefore reviews lesser than max length will be made equal using extra zeros at end. This is padding.\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=len_max)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
    "\n",
    "print(X_train.shape,X_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_acc', patience = 2)\n",
    "callback = [early_stopping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 48, 300)           4121700   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 48, 128)           219648    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 4,397,761\n",
      "Trainable params: 4,397,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model using Keras LSTM\n",
    "\n",
    "#Multilayer Perceptron (MLP) for multi-class softmax classification:\n",
    "#Let’s build what’s probably the most popular type of model in NLP at the moment: Long Short Term Memory network. \n",
    "#This architecture is specially designed to work on sequence data.\n",
    "#It fits perfectly for many NLP tasks like tagging and text classification.\n",
    "#It treats the text as a sequence rather than a bag of words or as ngrams.\n",
    "\n",
    "#Here’s a possible model definition:\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
    "model.add(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
    "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.005),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/6\n",
      "124848/124848 [==============================] - 413s 3ms/step - loss: 1.0113 - accuracy: 0.5947 - val_loss: 0.8593 - val_accuracy: 0.6489\n",
      "Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124848/124848 [==============================] - 193s 2ms/step - loss: 0.8169 - accuracy: 0.6667 - val_loss: 0.8186 - val_accuracy: 0.6605\n",
      "Epoch 3/6\n",
      "124848/124848 [==============================] - 166s 1ms/step - loss: 0.7543 - accuracy: 0.6879 - val_loss: 0.8097 - val_accuracy: 0.6679\n",
      "Epoch 4/6\n",
      "124848/124848 [==============================] - 168s 1ms/step - loss: 0.7173 - accuracy: 0.7026 - val_loss: 0.8178 - val_accuracy: 0.6720\n",
      "Epoch 5/6\n",
      "124848/124848 [==============================] - 166s 1ms/step - loss: 0.6947 - accuracy: 0.7100 - val_loss: 0.8222 - val_accuracy: 0.6735\n",
      "Epoch 6/6\n",
      "124848/124848 [==============================] - 167s 1ms/step - loss: 0.6773 - accuracy: 0.7164 - val_loss: 0.8351 - val_accuracy: 0.6756\n"
     ]
    }
   ],
   "source": [
    "#This is done for learning purpose only. One can play around with different hyper parameters combinations\n",
    "#and try increase the accuracy even more. For example, a different learning rate, an extra dense layer \n",
    "# before output layer, etc. Cross validation could be used to evaluate the model and grid search \n",
    "# further to find unique combination of parameters that give maximum accuracy. This model has a validation\n",
    "#accuracy of around 66.5%\n",
    "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=6, batch_size=256, verbose=1, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU1fnH8c+TQIjsqygETBSwbAFiRNwQXFBwQcEKWKxohWrd+rNSwboVEWjrQquiFQWlRSgVUVQKVcS6IossgoggoARQVtm3wPn9cSZkCJNkgExukvm+X6/7ysy9d+484zLPnHPueY455xAREckrIegARESkZFKCEBGRiJQgREQkIiUIERGJSAlCREQiKhd0AEWldu3aLjU1NegwRERKlblz5250ztWJdKzMJIjU1FTmzJkTdBgiIqWKmX2X3zF1MYmISERKECIiEpEShIiIRFRmxiBEpHjs37+frKws9uzZE3QochSSk5NJSUmhfPnyUb9GCUJEjkpWVhZVqlQhNTUVMws6HImCc45NmzaRlZVFWlpa1K9TF5OIHJU9e/ZQq1YtJYdSxMyoVavWUbf6lCBE5KgpOZQ+x/LvTAkiR3Z20BGIiJQoShAAffrAL38ZdBQiEoVNmzbRunVrWrduzUknnUT9+vUPPd+3b19U17jppptYunRpgec8++yzjB07tihC5rzzzmP+/PlFcq3ipEFqgPr1YcgQ+P3voXXroKMRkQLUqlXr0JftI488QuXKlbn33nsPO8c5h3OOhITIv4FHjx5d6Pvcfvvtxx9sKacWBED//lCjBtx/f9CRiMgxWr58OS1atODWW28lIyODdevW0a9fPzIzM2nevDmDBg06dG7OL/rs7GyqV6/OgAEDaNWqFWeffTbr168H4IEHHmD48OGHzh8wYABt27bl9NNP59NPPwVg586ddO/enVatWtGrVy8yMzOjbins3r2bG2+8kZYtW5KRkcGHH34IwJdffsmZZ55J69atSU9PZ8WKFWzfvp3OnTvTqlUrWrRowWuvvVaU/+jypRYEQPXqMGAA3HcffPghtG8fdEQipUeHDkfuu+46+M1vYNcu6NLlyON9+vht40a49trDj33wwTGH8tVXXzF69Gief/55AIYNG0bNmjXJzs6mY8eOXHvttTRr1uyw12zdupULLriAYcOGcc899zBq1CgGDBhwxLWdc8yaNYvJkyczaNAgpk6dytNPP81JJ53ExIkTWbBgARkZGVHH+re//Y2kpCS+/PJLFi9eTJcuXVi2bBkjRozg3nvvpUePHuzduxfnHG+++Sapqan85z//ORRzcYhZC8LMRpnZejNblM9xM7O/mdlyM1toZhlhx240s2Wh7cZYxXiYO+6AevXgsceK5e1EpOiddtppnHnmmYeejxs3joyMDDIyMliyZAlfffXVEa854YQT6Ny5MwBnnHEGq1atinjtbt26HXHOxx9/TM+ePQFo1aoVzZs3jzrWjz/+mBtuuAGA5s2bU69ePZYvX84555zD4MGD+fOf/8zq1atJTk4mPT2dqVOnMmDAAD755BOqVasW9fscj1i2IF4GngHG5HO8M9A4tJ0FPAecZWY1gYeBTMABc81ssnNuSwxjhYoV4d//hiZNYvo2ImVOQb/4K1Ys+Hjt2sfVYsirUqVKhx4vW7aMv/71r8yaNYvq1avTu3fviPMAkpKSDj1OTEwkO587GitUqHDEOc65Y441v9fecMMNnH322bzzzjtccsklvPLKK7Rv3545c+YwZcoU+vfvzxVXXMH9xdAlHrMWhHPuQ2BzAad0BcY4byZQ3cxOBi4F3nXObQ4lhXeBy2IV52HOOcf/B+scHDxYLG8pIrGxbds2qlSpQtWqVVm3bh3Tpk0r8vc477zzmDBhAuDHDiK1UPLTvn37Q3dJLVmyhHXr1tGoUSNWrFhBo0aNuPvuu7n88stZuHAha9asoXLlytxwww3cc889fPHFF0X+WSIJcgyiPrA67HlWaF9++49gZv2AfgANGzYsmqh+/BGuvBJ++1u4/vqiuaaIFLuMjAyaNWtGixYtOPXUUzn33HOL/D3uvPNOfvnLX5Kenk5GRgYtWrTIt/vn0ksvPVQH6fzzz2fUqFH8+te/pmXLlpQvX54xY8aQlJTEq6++yrhx4yhfvjz16tVj8ODBfPrppwwYMICEhASSkpIOjbHEmh1PE6nQi5ulAm8751pEOPYOMNQ593Ho+XTg98CFQAXn3ODQ/geBXc65Jwp6r8zMTFckCwYdPAhnnAHbtsGSJRDW/BQR/2u3adOmQYdRImRnZ5OdnU1ycjLLli2jU6dOLFu2jHLlSub9P5H+3ZnZXOdcZqTzg7zNNQtoEPY8BVhbwP7ikZDgB6pXrICXXiq2txWR0mfHjh2ce+65tGrViu7du/P3v/+9xCaHYxHkJ5kM3GFm4/GD1Fudc+vMbBowxMxqhM7rBAws1sg6d4bzz4dBg/wM67CBLxGRHNWrV2fu3LlBhxEzsbzNdRzwGXC6mWWZ2a/M7FYzuzV0yhRgBbAcGAn8BsA5txl4FJgd2gaF9hUfMxg6FH74AUaOLNa3FhEpKWLWgnDO9SrkuAMizmV3zo0CRsUirqidey5MmuRbEyIicajsdJbFwtVX+7/O+VaFiEgcUS2mwnzwATRtCuvWBR2JiEixUoIoTIMG8O238OijQUciIkCHDh2OmPQ2fPhwfvOb3xT4usqVKwOwdu1ars1b/yns2oXdLj98+HB27dp16HmXLl346aefogm9QI888giPP/74cV+nKClBFOa006BfPz9Y/e23QUcjEvd69erF+PHjD9s3fvx4evUqcNjzkHr16h1XNdS8CWLKlClUr179mK9XkilBROOBB6B8eXjooaAjEYl71157LW+//TZ79+4FYNWqVaxdu5bzzjuPHTt2cNFFF5GRkUHLli158803j3j9qlWraNHCz93dvXs3PXv2JD09nR49erB79+5D5912222HSoU//PDDgK/AunbtWjp27EjHjh0BSE1NZePGjQA8+eSTtGjRghYtWhwqFb5q1SqaNm1K3759ad68OZ06dTrsfQoT6Zo7d+7k8ssvP1T++1//+hcAAwYMoFmzZqSnpx+xRsax0CB1NE4+Ge6+G4YN88lCs0hFAF+RpqgXSmvdGkLfgxHVqlWLtm3bMnXqVLp27cr48ePp0aMHZkZycjKTJk2iatWqbNy4kXbt2nHVVVflux7zc889R8WKFVm4cCELFy48rFz3Y489Rs2aNTlw4AAXXXQRCxcu5K677uLJJ59kxowZ1K5d+7BrzZ07l9GjR/P555/jnOOss87iggsuoEaNGixbtoxx48YxcuRIrrvuOiZOnEjv3r0L/WeR3zVXrFhBvXr1eOeddwBf/nvz5s1MmjSJr7/+GjMrkm4vtSCi9fvfwxtvwM9+FnQkInEvvJspvHvJOcf9999Peno6F198MWvWrOHHH3/M9zoffvjhoS/q9PR00tPTDx2bMGECGRkZtGnThsWLFxdaiO/jjz/mmmuuoVKlSlSuXJlu3brx0UcfAZCWlkbr0GqVBZUUj/aaLVu25L333uO+++7jo48+olq1alStWpXk5GRuueUWXn/9dSpWrBjVexRELYho1agBXbv6x7rtVQQo+Jd+LF199dWHqpru3r370C//sWPHsmHDBubOnUv58uVJTU2NWOI7XKTWxcqVK3n88ceZPXs2NWrUoE+fPoVep6C6djmlwsGXC4+2iym/azZp0oS5c+cyZcoUBg4cSKdOnXjooYeYNWsW06dPZ/z48TzzzDO8//77Ub1PftSCOFrDh/sVsmJY5FBECla5cmU6dOjAzTfffNjg9NatWznxxBMpX748M2bM4LvvvivwOuEltxctWsTChQsBXyq8UqVKVKtWjR9//PHQSm4AVapUYfv27RGv9cYbb7Br1y527tzJpEmTOP/884/rc+Z3zbVr11KxYkV69+7NvffeyxdffMGOHTvYunUrXbp0Yfjw4VEvfVoQtSCOVnIyTJ0KU6bA5ZcHHY1I3OrVqxfdunU77I6mX/ziF1x55ZVkZmbSunVrflZIl/Btt93GTTfdRHp6Oq1bt6Zt27aAXx2uTZs2NG/e/IhS4f369aNz586cfPLJzJgx49D+jIwM+vTpc+gat9xyC23atIm6Owlg8ODBhwaiAbKysiJec9q0afTv35+EhATKly/Pc889x/bt2+natSt79uzBOcdTTz0V9fvmJ6blvotTkZX7Lsz+/X6QunJl+OILX/1VJI6o3HfpVZrKfZdO5cv7Kq8LFkDo1jIRkbJICeJY9OwJ6el+XoSWJhWRMkpjEMciIQH+/neoUEFdTBKXnHP5zi2QkulYhhOUII5Vu3ZBRyASiOTkZDZt2kStWrWUJEoJ5xybNm0iOTn5qF6nBHE89u+HW26BFi2gf/+goxEpFikpKWRlZbFhw4agQ5GjkJycTEpKylG9RgnieJQvDxs3wpAhPlHUqFH4a0RKufLly5OWlhZ0GFIM1IF+vIYMgZ9+gr/8JehIRESKlBLE8WrVCnr18jOstaiQiJQhShBFYdAgPx4xZEjQkYiIFJmYJggzu8zMlprZcjMbEOH4KWY23cwWmtkHZpYSduyAmc0PbZNjGedxa9QIxoyBgQODjkREpMjEbJDazBKBZ4FLgCxgtplNds6F18x9HBjjnHvFzC4EhgI3hI7tds61jlV8RS7K1axEREqLWLYg2gLLnXMrnHP7gPFA1zznNAOmhx7PiHC8dPn2W+jYEUIVIUVESrNYJoj6wOqw51mhfeEWAN1Dj68BqphZrdDzZDObY2YzzezqGMZZdGrWhHnz/KpzIiKlXCwTRKQplnnnet8LXGBm84ALgDVAduhYw1CFweuB4WZ22hFvYNYvlETmlIhJOzVqwH33wVtvwSefBB2NiMhxiWWCyAIahD1PAdaGn+CcW+uc6+acawP8IbRva86x0N8VwAdAm7xv4Jx7wTmX6ZzLrFOnTkw+xFG76y6oW9cPWJeRUuoiEp9imSBmA43NLM3MkoCewGF3I5lZbTPLiWEgMCq0v4aZVcg5BzgXKHhB2JKiUiV48EH46COYNi3oaEREjlnM7mJyzmWb2R3ANCARGOWcW2xmg4A5zrnJQAdgqJk54EPg9tDLmwJ/N7OD+CQ2LM/dTyVb375w4AAc53KDIiJB0opyIiJxTCvKBWXqVOjc2c+yFhEpZZQgYik72yeJ0aODjkRE5KgpQcTS5ZfDOefAH/8Iu3cHHY2IyFFRgoglMxg6FNauhWeeCToaEZGjogQRa+3b+3GIoUNh69agoxERiZpWlCsOw4bB4sVQpUrQkYiIRE0Jojikp/tNRKQUURdTcXriCRXyE5FSQwmiOH3zDfz5z7ByZdCRiIgUSgmiOD30ECQmwsMPBx2JiEihlCCKU/36cOed8M9/wqJFQUcjIlIgJYjiNmAAVK0Kf/hD0JGIiBRIdzEVt5o1YcQISE0NOhIRkQIpQQTh+uuDjkBEpFDqYgrK1q1w223w3/8GHYmISERKEEE54QRf6XXAADh4MOhoRESOoAQRlKQkGDQI5s2D114LOhoRkSMoQQTp+uuhRQs/u1qLColICaMEEaTERHjsMVi2DF5+OehoREQOowQRtCuv9AsKXXxx0JGIiBxGt7kGzcyX4BARKWFi2oIws8vMbKmZLTezARGOn2Jm081soZl9YGYpYcduNLNloe3GWMZZInz9NfTooUWFRKTEiFmCMLNE4FmgM9AM6GVmzfKc9jgwxjmXDgwChoZeWxN4GDgLaAs8bGY1YhVribBrF0yYAI8/HnQkIiJAbFsQbYHlzrkVzrl9wHiga55zmgHTQ49nhB2/FHjXObfZObcFeBe4LIaxBi8jA667Dp56Cn78MehoRERimiDqA6vDnmeF9oVbAHQPPb4GqGJmtaJ8LWbWz8zmmNmcDRs2FFnggXn0Udizx9/ZJCISsFgmCIuwz+V5fi9wgZnNAy4A1gDZUb4W59wLzrlM51xmnTp1jjfe4DVpAjffDM8/D6tWBR2NiMS5WN7FlAU0CHueAqwNP8E5txboBmBmlYHuzrmtZpYFdMjz2g9iGGvJ8dBDcNJJUKNsD7mISMkXyxbEbKCxmaWZWRLQE5gcfoKZ1TaznBgGAqNCj6cBncysRmhwulNoX9mXkuJLcFSrFnQkIhLnYpYgnHPZwB34L/YlwATn3GIzG2RmV4VO6wAsNbNvgLrAY6HXbgYexSeZ2cCg0L74MXUq9O8fdBQiEsfMuSO69kulzMxMN2fOnKDDKDqDB8ODD8Jnn0G7dkFHIyJllJnNdc5lRjqmUhsl1W9/CyeeCPffD2UkiYtI6aIEUVJVruzXrZ4xA957L+hoRCQOKUGUZL/+NZxyCgwcqFaEiBQ7FesrySpUgCefhC1b/KpziYlBRyQicUQJoqTr1i3oCEQkTqmLqTQ4cACefhrGjw86EhGJI2pBlAYJCTB2LKxZA1dfDcnJQUckInFALYjSwAyGDoWsLBgxIuhoRCROKEGUFh07wiWXwJAhsG1b0NGISBxQgihNhgyBTZvgiSeCjkRE4oASRGmSmenLb1xwQdCRiEgc0CB1aTNoUNARiEicUAuiNNq8Ge69F777LuhIRKQMUwuiNNq5E555xieKUaMKP19E5BioBVEaNWgAt98Or7wCX30VdDQiUkYpQZRWAwdCpUp+0FpEJAaUIEqr2rXhd7+D11+HWbOCjkZEyqC4TxAHD8Idd8C77/rHpco998CNN0LNmkFHIiJlUNwniFWrYNw46NQJGjXyc9HWrQs6qihVqQIvv+wDFxEpYlElCDM7zcwqhB53MLO7zKx6bEMrHqee6mvgvfoqpKb6RdwaNPA18aZM8YVUS7ylS2HAAC0qJCJFKtoWxETggJk1Al4C0oBXYxZVMUtOhl694P334ZtvfNf+Z5/B5ZdDWho88gh8/33QURbgs8/gT3/y4xEiIkUk2gRx0DmXDVwDDHfO/R9wcmEvMrPLzGypmS03swERjjc0sxlmNs/MFppZl9D+VDPbbWbzQ9vzR/Ohjkfjxv67dvVqeO01aNbMT15OTfUJ4403YP/+4oomSjfcAE2bwgMPQHZ20NGISBkRbYLYb2a9gBuBt0P7yhf0AjNLBJ4FOgPNgF5m1izPaQ8AE5xzbYCeQHgt62+dc61D261RxllkkpKge3eYOhVWrPBdT/PnwzXXQMOGcP/9fn+JkJgIgwfD11/DmDFBRyMiZUS0CeIm4GzgMefcSjNLA/5ZyGvaAsudcyucc/uA8UDXPOc4oGrocTVgbZTxFKvUVHj0UV/ZYvJkXzPvT3+C007zFbgnTIB9+wIO8ppr4MwzfX/Ynj0BByMiZUFUCcI595Vz7i7n3DgzqwFUcc4NK+Rl9YHVYc+zQvvCPQL0NrMsYApwZ9ixtFDX0//M7PxIb2Bm/cxsjpnN2bBhQzQf5biUKwdXXglvveWTxaBBsGwZ9OgB9etD//5+vDgQZj5r/fznJbAPTERKo2jvYvrAzKqaWU1gATDazJ4s7GUR9uW9zaYX8LJzLgXoAvzDzBKAdUDDUNfTPcCrZlY1z2txzr3gnMt0zmXWqVMnmo9SZFJS/CTmb7/13VDt28Pw4fCzn/lq3GPHBvBDvmNHv1ZElSrF/MYiUhZF28VUzTm3DegGjHbOnQFcXMhrsoAGYc9TOLIL6VfABADn3GdAMlDbObfXObcptH8u8C3QJMpYi1ViIlx6KUyc6Ae2hw3zt8327g316sHdd8OiRcUc1PTpMHp0Mb+piJQ10SaIcmZ2MnAduYPUhZkNNDazNDNLwg9CT85zzvfARQBm1hSfIDaYWZ3QIDdmdirQGCgpQ8L5OukkuO8+f6vs9Ok+cTz/PLRsCWef7b+zd+4shkBGjIC77oJi6HYTkbIr2gQxCJiGv7NoduhLe1lBLwjdFntH6HVL8HcrLTazQWZ2Vei03wF9zWwBMA7o45xzQHtgYWj/a8CtzrnNR/vhgpKQABde6Gdor1kDTz4JP/0EN9/sWxW33QZffBHDAAYPhl27YOjQGL6JiJR15srI7NvMzEw3Z86coMPIl3PwyScwcqS/62nPHjjjDOjb10/Sq3rECMtxuvlmPxCybJm/L1dEJAIzm+ucy4x0LNpB6hQzm2Rm683sRzObaGYpRRtm2WYG553nl3BYuxaeftrfbHTrrb5V8atfweefF2G1jEce8X//+MciuqCIxJtou5hG48cP6uFvVX0rtE+OQY0avoLs/Pk+KfTsCf/6F7RrB61a+eSxZctxvknDhv42q4yMIolZREqePXv8rfULFsTm+lF1MZnZfOdc68L2BamkdzEVZvt2P2YxciTMmePrQ/38574L6rzzfAtEROLLnj2+DtyqVZG3nMrTZ50FM2ce23sU1MUU7ZrUG82sN34gGfz8hU3HFo5EUqUK9Ovnt3nzfKIYOxb+8Q8/t6JvX/jlL/06QUclO9v3a7Vpo9aESAmzd6+fdFtYAshRrpzvHEhNhc6d/d+0NGgSo0kA0bYgGgLP4MttOOBT4C7nXImpcVraWxCR7NwJ//43vPCCL9ialOQravTt6+fEJUTTQbhtm68J0rq1XxVJRIrN3r0FtwDW5pkZFp4AIm316vm5V0WpoBbEMd/FZGa/dc4NP67IilBZTBDhFi2CF1/0tfi2bPHf+bfcAn36+PkXBXrqKb/63HvvwUUXFUe4InFh714/QXblyugSQGJi5ASQlha7BFCYWCWI751zJeb+ybKeIHLs2eOXfXjhBfjf/3LrQ/Xr5wsHRvyPa88e3wY9+WTfUakBDZGo5CSAgloA4V+h+SWA8BZAuWg79otJrBLEaudcg8LPLB7xkiDCffONb1W8/LKfNN2wob9d9uabfa2ow4we7Q+8/rrvpxIR9u07PAHkbQlESgANGkT+8k9LK5kJoDBqQZRx+/bBm2/6ge133/VjE126+LGKLl1C/8FmZ/uys7ff7qd5i8SBvAkg77ZmTfQJIDXVV20ubQmgMMecIMxsO0dWYAVfqfUE51yJ+UcVzwki3MqV8NJLMGqUvwOiXj246SbfskhLCzo6kegdPAi7d/ubNY5m27gx/wSQkFBwAkhJKXsJoDAxaUGUNEoQh8vOhnfe8a2K//zH/09yySXQ9xc7uWr1CJLuvQsqVAg6TCnlDhw4+i/waLddu44uloQEqFTJT0QNH/jN2wIoX+BamPFHCSLOrV7tWxQvveQfn8iP9O6whuY3ZHDiiRy2VawYdLRS1Pbvj92X+NGueVKunP8SL2irXLnwcyJtFSro/otjoQQhgP+199//wgs3fsxbG9pxIMI8yUqVDk8YdetyRBLJ2WrVir/meJCcy+1CiXbbsuXol8NNSiq6L+28W1JSbP7ZyLEripnUUgYkJvrZl52nJLO7XQ3WV23E+jsGsf7My1m/MYH16+HHH2H9er99/70v+7F+vU8ueZn5JBEpeURKLFWq6BdeuN27YdOmo/vC37s38rUSEvy/i9q1/dakCZxzju9uOdovdyV9yaEWRLxauNAvTLFjB8ydW+C3wsGDfj2LnMQRvoUnlJztp58iX6dChfxbI3mTSp06pevX5r59kb/sC0oABS0eVbPm4V/4hW3Vq0c5s14kD7Ug5Ejp6fDRR34CRbly/lv9L3+BAQOOWNM6IcF/YdWs6etCFWbfPn/ZSAklPKksWuT/5veruHr1ghNKeGIpyi/IAwdg8+aj+2W/bVv+16taNfeLvG5daN684C/7GjX0K15KBrUgxBs/Hq6/3s+2fuopX0q2GPqDnPOVbPNLJnlbKZs2RV4zo1w53+ooKJFUq+bzYDT99vn9b1GxYvS/6mvX9q2A0tQSkvijQWqJzuef+26nefP8PbHPPBO7MpHHKDvbJ4mCEkp4UimoGycpySeVo/myP+GE4vusIsVBXUwSnbPOgtmz4fnn4f774b77YNKkoKM6TLlyvpumbt3ozt+5M7e7a+tW332T84VfqZIGzUUKogQhh0tM9OU4unf3P9cBVqyAJUvg8suDje0Y5NyZk5oadCQipU9M73sws8vMbKmZLTezARGONzSzGWY2z8wWmlmXsGMDQ69bamaXxjJOieCkk3Ir/j3+OFxxhS/y9913wcYlIsUmZgnCzBKBZ4HOQDOgl5k1y3PaA8AE51wboCcwIvTaZqHnzYHLgBGh60kQhg+HYcP8LLumTf3jo519JSKlTixbEG2B5c65Fc65fcB4oGuecxxQNfS4GpCzvEZXYLxzbq9zbiWwPHQ9CUJSkh+PWLIELrsMBg70SUJEyrRYjkHUB1aHPc8CzspzziPAf83sTqAScHHYa8OX4M4K7TuMmfUD+gE0bFhiKo+XXQ0b+vUkpkzx03QBFi/2t/cUuqydiJQ2sWxBRLo/JO89tb2Al51zKUAX4B9mlhDla3HOveCcy3TOZdapU+e4A5YodeniZ6Y552uJn346PP107qC2iJQJsUwQWUD4inMp5HYh5fgVMAHAOfcZkAzUjvK1EjQzGDsW2rWDu+6Ctm39XAoRKRNimSBmA43NLM3MkvCDzpPznPM9cBGAmTXFJ4gNofN6mlkFM0sDGgOzYhirHKvGjWHqVJgwwc9OO/tsv6ydiJR6MUsQzrls4A5gGrAEf7fSYjMbZGZXhU77HdDXzBYA44A+zluMb1l8BUwFbnfORagnKiWCmS/N8fXXMHQodOjg969Y4Sv9iUippFIbEhvbtvkyHY0awYgRvjigiJQ4BZXaUIFgiY3KlX1rYulSyMiAe+7xVflEpNRQgpDYSEjwdzgtXQq33OIn2/3sZ7BW9xqIlBZKEBJbNWv64n8zZ0KvXr6cOKg1IVIKKEFI8Wjb1td0MoOVK/2ku4ce8utuikiJpAQhxa9SJV/879FH/fJq77wTdEQiEoEShBS/E0+Ef/wD3n8fkpN9suje3a/1KSIlhtaDkOB07Ajz5/slTjdu9GtRgJ87UVQLTIvIMdP/hRKsnEqxf/mLf/7pp9CyJcyYEWxcIqIEISXM/v1+4PrCC6F3b/jhh6AjEolbShBSslxwgS8h/uCD8O9/+0qxI/re1hsAAA9bSURBVEcGHZVIXFKCkJLnhBNg0CD48ks46yz46aegIxKJSxqklpKrSROYNi234N/48X5sYuhQPwFPRGJKLQgp2cxy725auRJeesl3O40erUqxIjGmBCGlx8CBMG+eTxA33wznn++7oUQkJpQgpHRp2RI+/NC3IL75xm8iEhMag5DSJyEB+vSBa66BqlX9vuee8+MS113nu6VE5LipBSGlV7VqPhkcPAivvgo9e0KnTmpViBQRJQgp/RIS4IMP4JlnYNYs3w314IOqFCtynJQgpGxITITbb/cLFF13HQwZ4ifcicgxU4KQsuWkk3yl2K+/hszQMrsvvADffx9sXCKlkBKElE2NG/u/GzbA734HTZv6VsWmTcHGJVKKxDRBmNllZrbUzJab2YAIx58ys/mh7Rsz+yns2IGwY5NjGaeUYXXq+K6mSy+FP/zBL3natSt8+23QkYmUeDG7zdXMEoFngUuALGC2mU12zn2Vc45z7v/Czr8TaBN2id3Oudaxik/iSMOG8Prrfu2Jf/4TXnsNqlf3xz74AJzzRQK1BoXIYWL5f0RbYLlzboVzbh8wHuhawPm9gHExjEfiXevWfl3slSuhVi2/b8gQX1r8lFP8uhSamS1ySCwTRH1gddjzrNC+I5jZKUAa8H7Y7mQzm2NmM83s6nxe1y90zpwNGzYUVdxS1oVPpHvjDV8EsFUreOIJSE+HG28MLjaREiSWCSLSdFaXz7k9gdecc+GLEjd0zmUC1wPDzey0Iy7m3AvOuUznXGadOnWOP2KJPxUrQo8e8PbbsG4dPP00XB36PbJlix+7GD0atm4NNk6RAMQyQWQBDcKepwBr8zm3J3m6l5xza0N/VwAfcPj4hEjRq1MH7rjDl/AA3xW1YoUvDHjSST6RTJ4M+/YFG6dIMYllgpgNNDazNDNLwieBI+5GMrPTgRrAZ2H7aphZhdDj2sC5wFd5XysSUxkZvmzHzJlwyy3w/vv+DqhVq/zxrVv9ALdIGRWzBOGcywbuAKYBS4AJzrnFZjbIzK4KO7UXMN65w/5PawrMMbMFwAxgWPjdTyLFxsyvavf007B2rb/rqUkTf6xvX2jUCB5+WPWfpEwyV0Z+AWVmZro5c+YEHYbEk1df9eMT06f7lkTbtnDXXfCLXwQdmUjUzGxuaLz3CLrxW+RYXX89vPsurF7tb5/dtw+WLPHH9u/3d0ft2hVsjCLHQS0IkaKUnQ3lysF//gNdukDlytCtG/Tu7edb5CyfKlJCqAUhUlzKhYoTXHqpH6/o2RPefNOvU9Gggb8zSqSUUIIQiYWEBF++Y+RI+OEHX96jSxc/YxvgL3/xs7hz7ogSKYGUIERiLTkZuneHF1/Mrfc0c6YvHpiWBu3b+5LkW7YEG6dIHkoQIkGYONFPwhs82Jck//WvoX9/f8w52Ls32PhEUIIQCU5amm9FfPUVzJmTmyDmzfMzt/v1gw8/9GtuiwRACUIkaGZwxhlw+un+eXIyXHmln2dxwQU+kdx/v7qgpNgpQYiUNM2awZgx8OOPMHYsNG8Ozz8PFSr447Nn+8KCIjGmBCFSUlWq5CfjTZniJ+NVrOj333QTpKT4W2fHjIHt24ONU8osJQiR0qBSpdzHEyf6sYvly/3aFXXr+ttmRYqYEoRIaXP66TBokF9X+5NPoE8faNzYH8vK8vWgZs1SpVk5bjFbk1pEYswMzjnHbznmzvVzKp5+2ieNHj3g/PP9YHfOGIZIlJQgRMqSrl394PbEifDPf8Jjj/n9W7b4BPHWW35md7t2fjBctaGkAOpiEilrqlXzq+C9/z789BN89JHfB/CPf/j5FenpUL06XHRRbhIRyUPVXEXiiXN+7GLmzNytRg1fthzg2mv9PIx27eDss30iKV8+2Jglpgqq5qouJpF4YuZXwWvUyJcgh9yZ2s75arTvv+/nX4BPFvfeC48+6p//8IOf5S1xQQlCJN7lFBA084scOefnXeS0MJo398d/+AFOPtmXLW/XLnfLyPCJRMocJQgROZwZNGzot+uuy92flATDh+cmjn//2+9/+WU/HyMry493tGsHqan+OlKqKUGISHRq1oS77/Yb+BbFzJk+IQBMnQp9+/rHdevmtjD69oVatYKJWY5LTAepzewy4K9AIvCic25YnuNPAR1DTysCJzrnqoeO3Qg8EDo22Dn3SkHvpUFqkYBlZ8OXX+a2MD77DJYtg40bfYJ45ZXchHL22X6ehloZgStokDpmCcLMEoFvgEuALGA20Ms591U+598JtHHO3WxmNYE5QCbggLnAGc65fMtZKkGIlEBbtvi7pAAeesh3UeXUjqpRAzp08HM2zGD/ft0xFYCg1qRuCyx3zq1wzu0DxgNdCzi/FzAu9PhS4F3n3OZQUngXuCyGsYpILOQkB/DlQbZsgUWL/Op63btDlSq5rYiOHf2A+K9+5ZdqXbQIDhwIJm4BYjsGUR9YHfY8Czgr0olmdgqQBrxfwGvrR3hdP6AfQMOGDY8/YhGJrcREnwRyEkG4rl3hf/+DN9+EUaP8vp//HCZM8I+nT4dWraB27eKNOY7FMkFE6lzMrz+rJ/Cacy7n50JUr3XOvQC8AL6L6ViCFJESon9/vznnK9XOnAknnuiPbdoEF1/sHzdqlDsA3rkznHpqcDGXcbFMEFlAg7DnKcDafM7tCdye57Ud8rz2gyKMTURKKjM/gJ1ToRZ8V9T//pc7AP7ee77W1MiRPkGsWgUjRvikceaZfr0MDYAft1gOUpfDD1JfBKzBD1Jf75xbnOe804FpQJoLBRMapJ4LZIRO+wI/SL05v/fTILVIHMmZzFelih/nePttP6axb58/Xq2aL0b44ov+76ZNfhC8bl0ljjwCKbXhnMs2szvwX/6JwCjn3GIzGwTMcc5NDp3aCxjvwjKVc26zmT2KTyoAgwpKDiISZ3Im8+W44grYtg3mzYMvvoDFi/0gd06RwlGj4Pe/97fb5oyBNG/uV+fLWalPjqBifSJS9i1e7Ae5cxLH4sWwc6ffkpLgkUf8LPAWLQ5PINWrBx15zKlYn4jEt5wv/BzO+XUzkpL88ypVYMcOeOklnzQA6tWDNWv841de8UUNmzf3XVaVKxdv/AFRC0JEJMfBg/D9976FsX079Ozp97duDQsW5J6XmgrdusETT/jnS5f6Lq8TTij2kI+XWhAiItFISPBf/qmph++fOxdWrDi8i6pKFX/MOX/n1M6d/o6qnG6qSy/1y72WYkoQIiKFSUzMvfX26qsPP3bggO+aWrw4N4G89ZYfSD//fNi61deeat788DGORo1KfGkRJQgRkeNRrpyf8f3zn+fu27vXb+C7qpo0gfnzfd2pnG79ESPgttv87bpjxuQmkLS0ErNWuBKEiEhRq1DBb+An7b3xhn+8axd8/bVvZZx7rt+3YAE88EDua5OToWlT3ypp08ZXw92xw49xJMSyfN6RlCBERIpLxYp+Bb6MjNx9OXM4lizJHd9YtMivvwF+xvj//Z+/c6pZs9xuqr59c8dBYkR3MYmIlGTffAMzZuSOcSxeDOvX+1ZFxYq+Su7ttx/zoky6i0lEpLRq0sRv4TZvzp0BXr9+bmujiClBiIiUNuEJIW/Z9CJUvCMeIiJSaihBiIhIREoQIiISkRKEiIhEpAQhIiIRKUGIiEhEShAiIhKREoSIiERUZkptmNkG4LvjuERtYGMRhVNaxNtnjrfPC/rM8eJ4PvMpzrk6kQ6UmQRxvMxsTn71SMqqePvM8fZ5QZ85XsTqM6uLSUREIlKCEBGRiJQgcr0QdAABiLfPHG+fF/SZ40VMPrPGIEREJCK1IEREJCIlCBERiSjuE4SZjTKz9Wa2KOhYioOZNTCzGWa2xMwWm9ndQccUa2aWbGazzGxB6DP/MeiYiouZJZrZPDN7O+hYioOZrTKzL81svpnFxRrEZlbdzF4zs69D/1+fXWTXjvcxCDNrD+wAxjjnWgQdT6yZ2cnAyc65L8ysCjAXuNo591XAocWMmRlQyTm3w8zKAx8DdzvnZgYcWsyZ2T1AJlDVOXdF0PHEmpmtAjKdc3EzUc7MXgE+cs69aGZJQEXn3E9Fce24b0E45z4ENgcdR3Fxzq1zzn0RerwdWALUDzaq2HLejtDT8qGtzP8yMrMU4HLgxaBjkdgws6pAe+AlAOfcvqJKDqAEEdfMLBVoA3webCSxF+pqmQ+sB951zpX5zwwMB34PHAw6kGLkgP+a2Vwz6xd0MMXgVGADMDrUlfiimVUqqosrQcQpM6sMTAR+65zbFnQ8seacO+Ccaw2kAG3NrEx3J5rZFcB659zcoGMpZuc65zKAzsDtoS7ksqwckAE855xrA+wEBhTVxZUg4lCoH34iMNY593rQ8RSnUPP7A+CygEOJtXOBq0J98uOBC83sn8GGFHvOubWhv+uBSUDbYCOKuSwgK6xF/Bo+YRQJJYg4ExqwfQlY4px7Muh4ioOZ1TGz6qHHJwAXA18HG1VsOecGOudSnHOpQE/gfedc74DDiikzqxS68YJQN0snoEzfneic+wFYbWanh3ZdBBTZDSfliupCpZWZjQM6ALXNLAt42Dn3UrBRxdS5wA3Al6E+eYD7nXNTAowp1k4GXjGzRPyPognOubi47TPO1AUm+d9AlANedc5NDTakYnEnMDZ0B9MK4KaiunDc3+YqIiKRqYtJREQiUoIQEZGIlCBERCQiJQgREYlICUJERCJSghA5CmZ2IFQpNGcrslmrZpYaL1WFpXSI+3kQIkdpd6hkh0iZpxaESBEIrUPwp9C6E7PMrFFo/ylmNt3MFob+Ngztr2tmk0JrVCwws3NCl0o0s5GhdSv+G5r5LRIIJQiRo3NCni6mHmHHtjnn2gLP4CupEno8xjmXDowF/hba/zfgf865VvjaOYtD+xsDzzrnmgM/Ad1j/HlE8qWZ1CJHwcx2OOcqR9i/CrjQObciVAzxB+dcLTPbiF+gaX9o/zrnXG0z2wCkOOf2hl0jFV+KvHHo+X1Aeefc4Nh/MpEjqQUhUnRcPo/zOyeSvWGPD6BxQgmQEoRI0ekR9vez0ONP8dVUAX6BX+4UYDpwGxxazKhqcQUpEi39OhE5OieEVcEFmOqcy7nVtYKZfY7/4dUrtO8uYJSZ9cev/JVTafNu4AUz+xW+pXAbsC7m0YscBY1BiBSB0BhEpnNuY9CxiBQVdTGJiEhEakGIiEhEakGIiEhEShAiIhKREoSIiESkBCEiIhEpQYiISET/D1e99WcDVY6EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Visualize learning curve. Here learning curve is not ideal. It should be much smoother as it decreases.\n",
    "#As mentioned before, altering different hyper parameters especially learning rate can have a positive impact\n",
    "#on accuracy and learning curve.\n",
    "plt.plot(epoch_count, history.history['loss'], 'r--')\n",
    "plt.plot(epoch_count, history.history['val_loss'], 'b-')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-6036070009a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Actual'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Predicted'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m             )\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         ]\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# from BlockManager perspective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             val = sanitize_array(\n\u001b[1;32m--> 323\u001b[1;33m                 \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             )\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\Tensorflow\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Actual': y_val, 'Predicted': y_pred})\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(r\"C:\\Users\\Gaming\\Movie review data\\sentences.pickle\",\"wb\")\n",
    "pickle.dump(train_sentences, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(r\"C:\\Users\\Gaming\\Movie review data\\Target.pickle\",\"wb\")\n",
    "pickle.dump(y_target, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
