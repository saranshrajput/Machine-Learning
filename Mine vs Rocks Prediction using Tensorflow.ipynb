{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91999\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\91999\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\91999\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\91999\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\91999\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\91999\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = pd.read_csv(r'E:\\Downloads\\sonar.csv')\n",
    "    X = df[df.columns[0:59]].values\n",
    "    y = df[df.columns[60]].values\n",
    "    \n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)\n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels , n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels) , labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X , Y = read_dataset()\n",
    "X , Y = shuffle(X , Y , random_state = 1)\n",
    "train_x , test_x , train_y , test_y = train_test_split(X , Y , test_size = 0.2 , random_state =415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "training_epochs = 110\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history = np.empty(shape = [1] , dtype = float )\n",
    "n_dim = X.shape[1]\n",
    "n_class = 2\n",
    "model_path = 'E:\\ML\\mpdel.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91999\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60\n",
    "\n",
    "x = tf.placeholder(tf.float32 , [None , n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim , n_class]))               \n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32 , [None , n_class])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layer_perceptron(x , Weights , Biases):\n",
    "    layer_1 = tf.add(tf.matmul(x , Weights['h1']) , Biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1 , Weights['h2']) , Biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3 = tf.add(tf.matmul(layer_2 , Weights['h3']) , Biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    \n",
    "    layer_4 = tf.add(tf.matmul(layer_3 , Weights['h4']) , Biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    out_layer = tf.matmul(layer_4 , Weights['out'])+Biases['out']\n",
    "    print(out_layer)\n",
    "    return out_layer\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights = {\n",
    "    \n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim , n_hidden_1])),\n",
    "        \n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1 , n_hidden_2])),\n",
    "\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2 , n_hidden_3])),\n",
    "    \n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4 , n_class]))\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "Biases = {\n",
    "    \n",
    "        'b1': tf.Variable(tf.truncated_normal([ n_hidden_1])),\n",
    "        \n",
    "    'b2': tf.Variable(tf.truncated_normal([ n_hidden_2])),\n",
    "\n",
    "    'b3': tf.Variable(tf.truncated_normal([ n_hidden_3])),\n",
    "    \n",
    "    'b4': tf.Variable(tf.truncated_normal([ n_hidden_4])),\n",
    "\n",
    "    'out': tf.Variable(tf.truncated_normal([ n_class]))\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_4:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "y = multi_layer_perceptron( x , Weights , Biases)\n",
    "# print(y)\n",
    "print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0  -   cost :  None  -   MSE :  397.98822571189453  -   -Train_Accuracy :  0.54545456\n",
      "Epoch :  1  -   cost :  None  -   MSE :  2.1127435218557844  -   -Train_Accuracy :  0.54545456\n",
      "Epoch :  2  -   cost :  None  -   MSE :  3.269727602177581  -   -Train_Accuracy :  0.55757576\n",
      "Epoch :  3  -   cost :  None  -   MSE :  3.694009098881755  -   -Train_Accuracy :  0.5212121\n",
      "Epoch :  4  -   cost :  None  -   MSE :  3.9345458624731657  -   -Train_Accuracy :  0.5272727\n",
      "Epoch :  5  -   cost :  None  -   MSE :  4.006120133516738  -   -Train_Accuracy :  0.53939396\n",
      "Epoch :  6  -   cost :  None  -   MSE :  4.020376843991785  -   -Train_Accuracy :  0.54545456\n",
      "Epoch :  7  -   cost :  None  -   MSE :  4.046558774891416  -   -Train_Accuracy :  0.55151516\n",
      "Epoch :  8  -   cost :  None  -   MSE :  4.000507567048793  -   -Train_Accuracy :  0.58181816\n",
      "Epoch :  9  -   cost :  None  -   MSE :  3.9275624938010103  -   -Train_Accuracy :  0.57575756\n",
      "Epoch :  10  -   cost :  None  -   MSE :  3.79104650867527  -   -Train_Accuracy :  0.56969696\n",
      "Epoch :  11  -   cost :  None  -   MSE :  3.670207498394655  -   -Train_Accuracy :  0.56969696\n",
      "Epoch :  12  -   cost :  None  -   MSE :  3.5293410504252773  -   -Train_Accuracy :  0.56363636\n",
      "Epoch :  13  -   cost :  None  -   MSE :  3.479420070923347  -   -Train_Accuracy :  0.58181816\n",
      "Epoch :  14  -   cost :  None  -   MSE :  3.3705562658829225  -   -Train_Accuracy :  0.58787876\n",
      "Epoch :  15  -   cost :  None  -   MSE :  3.3248408368529527  -   -Train_Accuracy :  0.5939394\n",
      "Epoch :  16  -   cost :  None  -   MSE :  3.3140829601857718  -   -Train_Accuracy :  0.58787876\n",
      "Epoch :  17  -   cost :  None  -   MSE :  3.3236656849813695  -   -Train_Accuracy :  0.58787876\n",
      "Epoch :  18  -   cost :  None  -   MSE :  3.3926308691323226  -   -Train_Accuracy :  0.58787876\n",
      "Epoch :  19  -   cost :  None  -   MSE :  3.3650115488772845  -   -Train_Accuracy :  0.6\n",
      "Epoch :  20  -   cost :  None  -   MSE :  3.4849792931554435  -   -Train_Accuracy :  0.6242424\n",
      "Epoch :  21  -   cost :  None  -   MSE :  3.4625502482243413  -   -Train_Accuracy :  0.6242424\n",
      "Epoch :  22  -   cost :  None  -   MSE :  3.4765829802546326  -   -Train_Accuracy :  0.6242424\n",
      "Epoch :  23  -   cost :  None  -   MSE :  3.4948596352486097  -   -Train_Accuracy :  0.6121212\n",
      "Epoch :  24  -   cost :  None  -   MSE :  3.469784125896302  -   -Train_Accuracy :  0.6121212\n",
      "Epoch :  25  -   cost :  None  -   MSE :  3.262250206843094  -   -Train_Accuracy :  0.6181818\n",
      "Epoch :  26  -   cost :  None  -   MSE :  2.7554622537466655  -   -Train_Accuracy :  0.6\n",
      "Epoch :  27  -   cost :  None  -   MSE :  2.3322927599080265  -   -Train_Accuracy :  0.45454547\n",
      "Epoch :  28  -   cost :  None  -   MSE :  4.196276866960713  -   -Train_Accuracy :  0.630303\n",
      "Epoch :  29  -   cost :  None  -   MSE :  4.403113217032372  -   -Train_Accuracy :  0.6242424\n",
      "Epoch :  30  -   cost :  None  -   MSE :  4.259723937831711  -   -Train_Accuracy :  0.6242424\n",
      "Epoch :  31  -   cost :  None  -   MSE :  3.9104413452673388  -   -Train_Accuracy :  0.6606061\n",
      "Epoch :  32  -   cost :  None  -   MSE :  3.480941264151287  -   -Train_Accuracy :  0.58787876\n",
      "Epoch :  33  -   cost :  None  -   MSE :  3.436767485246804  -   -Train_Accuracy :  0.56969696\n",
      "Epoch :  34  -   cost :  None  -   MSE :  4.009017364669905  -   -Train_Accuracy :  0.6242424\n",
      "Epoch :  35  -   cost :  None  -   MSE :  4.294803965328954  -   -Train_Accuracy :  0.6727273\n",
      "Epoch :  36  -   cost :  None  -   MSE :  4.157612340307297  -   -Train_Accuracy :  0.6606061\n",
      "Epoch :  37  -   cost :  None  -   MSE :  3.7225929592668288  -   -Train_Accuracy :  0.630303\n",
      "Epoch :  38  -   cost :  None  -   MSE :  3.83569838765583  -   -Train_Accuracy :  0.6060606\n",
      "Epoch :  39  -   cost :  None  -   MSE :  3.6640757152610206  -   -Train_Accuracy :  0.6666667\n",
      "Epoch :  40  -   cost :  None  -   MSE :  3.888803241432038  -   -Train_Accuracy :  0.6787879\n",
      "Epoch :  41  -   cost :  None  -   MSE :  3.647315614770843  -   -Train_Accuracy :  0.6363636\n",
      "Epoch :  42  -   cost :  None  -   MSE :  3.764436839095318  -   -Train_Accuracy :  0.57575756\n",
      "Epoch :  43  -   cost :  None  -   MSE :  3.6120239165418413  -   -Train_Accuracy :  0.6666667\n",
      "Epoch :  44  -   cost :  None  -   MSE :  3.8626966555582696  -   -Train_Accuracy :  0.6666667\n",
      "Epoch :  45  -   cost :  None  -   MSE :  3.541327034296047  -   -Train_Accuracy :  0.6181818\n",
      "Epoch :  46  -   cost :  None  -   MSE :  3.6430376413890704  -   -Train_Accuracy :  0.58787876\n",
      "Epoch :  47  -   cost :  None  -   MSE :  3.8624499687435567  -   -Train_Accuracy :  0.6727273\n",
      "Epoch :  48  -   cost :  None  -   MSE :  4.10028216534325  -   -Train_Accuracy :  0.6848485\n",
      "Epoch :  49  -   cost :  None  -   MSE :  3.934602370693424  -   -Train_Accuracy :  0.58787876\n",
      "Epoch :  50  -   cost :  None  -   MSE :  3.787844448168935  -   -Train_Accuracy :  0.630303\n",
      "Epoch :  51  -   cost :  None  -   MSE :  4.226432516622908  -   -Train_Accuracy :  0.6969697\n",
      "Epoch :  52  -   cost :  None  -   MSE :  4.012917865605099  -   -Train_Accuracy :  0.6909091\n",
      "Epoch :  53  -   cost :  None  -   MSE :  3.888507249030919  -   -Train_Accuracy :  0.5939394\n",
      "Epoch :  54  -   cost :  None  -   MSE :  3.9861064099909633  -   -Train_Accuracy :  0.7030303\n",
      "Epoch :  55  -   cost :  None  -   MSE :  4.11292426367296  -   -Train_Accuracy :  0.6969697\n",
      "Epoch :  56  -   cost :  None  -   MSE :  4.035226604155357  -   -Train_Accuracy :  0.58181816\n",
      "Epoch :  57  -   cost :  None  -   MSE :  3.950154834439384  -   -Train_Accuracy :  0.6909091\n",
      "Epoch :  58  -   cost :  None  -   MSE :  4.004080716740035  -   -Train_Accuracy :  0.7151515\n",
      "Epoch :  59  -   cost :  None  -   MSE :  3.8162392965139267  -   -Train_Accuracy :  0.7151515\n",
      "Epoch :  60  -   cost :  None  -   MSE :  4.021042430027696  -   -Train_Accuracy :  0.5090909\n",
      "Epoch :  61  -   cost :  None  -   MSE :  4.94327961408839  -   -Train_Accuracy :  0.7151515\n",
      "Epoch :  62  -   cost :  None  -   MSE :  5.683324189785545  -   -Train_Accuracy :  0.7151515\n",
      "Epoch :  63  -   cost :  None  -   MSE :  6.2979416697723964  -   -Train_Accuracy :  0.7151515\n",
      "Epoch :  64  -   cost :  None  -   MSE :  5.337822742221518  -   -Train_Accuracy :  0.7090909\n",
      "Epoch :  65  -   cost :  None  -   MSE :  6.226037309170097  -   -Train_Accuracy :  0.6666667\n",
      "Epoch :  66  -   cost :  None  -   MSE :  9.386000091249215  -   -Train_Accuracy :  0.54545456\n",
      "Epoch :  67  -   cost :  None  -   MSE :  5.610815281378082  -   -Train_Accuracy :  0.6848485\n",
      "Epoch :  68  -   cost :  None  -   MSE :  4.464753498845674  -   -Train_Accuracy :  0.72727275\n",
      "Epoch :  69  -   cost :  None  -   MSE :  4.697347920371689  -   -Train_Accuracy :  0.72121215\n",
      "Epoch :  70  -   cost :  None  -   MSE :  4.983477190752059  -   -Train_Accuracy :  0.72121215\n",
      "Epoch :  71  -   cost :  None  -   MSE :  5.126808513668344  -   -Train_Accuracy :  0.6909091\n",
      "Epoch :  72  -   cost :  None  -   MSE :  5.365662026081655  -   -Train_Accuracy :  0.6424242\n",
      "Epoch :  73  -   cost :  None  -   MSE :  5.5887174230488466  -   -Train_Accuracy :  0.5939394\n",
      "Epoch :  74  -   cost :  None  -   MSE :  5.886448183546709  -   -Train_Accuracy :  0.6606061\n",
      "Epoch :  75  -   cost :  None  -   MSE :  5.964406770033672  -   -Train_Accuracy :  0.57575756\n",
      "Epoch :  76  -   cost :  None  -   MSE :  5.276109689641182  -   -Train_Accuracy :  0.56969696\n",
      "Epoch :  77  -   cost :  None  -   MSE :  5.089082111444243  -   -Train_Accuracy :  0.73939395\n",
      "Epoch :  78  -   cost :  None  -   MSE :  5.5847952340418905  -   -Train_Accuracy :  0.7030303\n",
      "Epoch :  79  -   cost :  None  -   MSE :  4.809441472935949  -   -Train_Accuracy :  0.4909091\n",
      "Epoch :  80  -   cost :  None  -   MSE :  5.396526392763215  -   -Train_Accuracy :  0.73333335\n",
      "Epoch :  81  -   cost :  None  -   MSE :  4.659341926770144  -   -Train_Accuracy :  0.72727275\n",
      "Epoch :  82  -   cost :  None  -   MSE :  4.961932065764506  -   -Train_Accuracy :  0.73333335\n",
      "Epoch :  83  -   cost :  None  -   MSE :  6.003042309141459  -   -Train_Accuracy :  0.6121212\n",
      "Epoch :  84  -   cost :  None  -   MSE :  5.212771425078037  -   -Train_Accuracy :  0.75757575\n",
      "Epoch :  85  -   cost :  None  -   MSE :  5.40049146215165  -   -Train_Accuracy :  0.7151515\n",
      "Epoch :  86  -   cost :  None  -   MSE :  5.243641703208138  -   -Train_Accuracy :  0.73333335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  87  -   cost :  None  -   MSE :  5.052825134946671  -   -Train_Accuracy :  0.73939395\n",
      "Epoch :  88  -   cost :  None  -   MSE :  3.8038256746364034  -   -Train_Accuracy :  0.53333336\n",
      "Epoch :  89  -   cost :  None  -   MSE :  4.826748896719078  -   -Train_Accuracy :  0.74545455\n",
      "Epoch :  90  -   cost :  None  -   MSE :  4.938385070934625  -   -Train_Accuracy :  0.75151515\n",
      "Epoch :  91  -   cost :  None  -   MSE :  5.108435280554637  -   -Train_Accuracy :  0.7090909\n",
      "Epoch :  92  -   cost :  None  -   MSE :  4.879653791935857  -   -Train_Accuracy :  0.4848485\n",
      "Epoch :  93  -   cost :  None  -   MSE :  4.5613761388375496  -   -Train_Accuracy :  0.74545455\n",
      "Epoch :  94  -   cost :  None  -   MSE :  3.7007041943600165  -   -Train_Accuracy :  0.76363635\n",
      "Epoch :  95  -   cost :  None  -   MSE :  3.4720351543791304  -   -Train_Accuracy :  0.73939395\n",
      "Epoch :  96  -   cost :  None  -   MSE :  3.038317542250204  -   -Train_Accuracy :  0.47878787\n",
      "Epoch :  97  -   cost :  None  -   MSE :  3.7601971763380426  -   -Train_Accuracy :  0.6\n",
      "Epoch :  98  -   cost :  None  -   MSE :  4.3807957387545216  -   -Train_Accuracy :  0.76969695\n",
      "Epoch :  99  -   cost :  None  -   MSE :  3.7838437523699633  -   -Train_Accuracy :  0.6606061\n",
      "Epoch :  100  -   cost :  None  -   MSE :  3.5973679634622404  -   -Train_Accuracy :  0.630303\n",
      "Epoch :  101  -   cost :  None  -   MSE :  3.3007870573384834  -   -Train_Accuracy :  0.58787876\n",
      "Epoch :  102  -   cost :  None  -   MSE :  2.8991094572483536  -   -Train_Accuracy :  0.7151515\n",
      "Epoch :  103  -   cost :  None  -   MSE :  2.8026764455692574  -   -Train_Accuracy :  0.58181816\n",
      "Epoch :  104  -   cost :  None  -   MSE :  2.7040755355259454  -   -Train_Accuracy :  0.6181818\n",
      "Epoch :  105  -   cost :  None  -   MSE :  3.1646348266566453  -   -Train_Accuracy :  0.74545455\n",
      "Epoch :  106  -   cost :  None  -   MSE :  2.9003380367359908  -   -Train_Accuracy :  0.7030303\n",
      "Epoch :  107  -   cost :  None  -   MSE :  2.854545890680973  -   -Train_Accuracy :  0.5030303\n",
      "Epoch :  108  -   cost :  None  -   MSE :  4.1210876077601  -   -Train_Accuracy :  0.77575755\n",
      "Epoch :  109  -   cost :  None  -   MSE :  3.03930422265183  -   -Train_Accuracy :  0.76969695\n",
      "Model save in file :%s E:\\ML\\mpdel.py\n",
      "Test_accuracy : 0.8095238\n",
      "MSE%4 3.03930422265183\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y, labels = y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for i in range(training_epochs):\n",
    "    sess.run(training_step , feed_dict = {x:train_x , y_:train_y})\n",
    "    cost = sess.run(training_step , feed_dict = {x:train_x , y_:train_y})\n",
    "    cost_history = np.append(cost_history , cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))\n",
    "    pred_y = sess.run(y , feed_dict = {x:test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse = sess.run(mse)\n",
    "    accuracy_history.append(accuracy)\n",
    "    accuracy = sess.run(accuracy , feed_dict = {x:train_x , y_:train_y})\n",
    "    print('Epoch : ',i,' - ',' cost : ',cost,' - ',' MSE : ' , mse , ' - ' , ' -Train_Accuracy : ' , accuracy )\n",
    "\n",
    "save_path = saver.save(sess,model_path) \n",
    "print(\"Model save in file :%s\" , save_path)\n",
    "\n",
    "# plt.plot(mse_history , 'r')\n",
    "# plt.show()\n",
    "# plt.plot(accuracy_history)\n",
    "# plt.show()\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))\n",
    "print(\"Test_accuracy :\" ,(sess.run(accuracy , feed_dict = {x:test_x , y_:test_y})))\n",
    "pred_y = sess.run(y , feed_dict = {x:test_x})\n",
    "mse = tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "print(\"MSE%4\" ,sess.run(mse))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
